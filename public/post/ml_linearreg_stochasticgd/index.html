<!DOCTYPE html>
<html lang="en-us">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
        


        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Linear Regression Part 8 - Stochastic Gradient Descent</title>
        
        <style>

    html body {
        font-family: 'Raleway', sans-serif;
        background-color: #f7f8fa;
    }

    :root {
        --accent: #660608;
        --border-width:  5px ;
    }

</style>


<link rel="stylesheet" href="//localhost:1313/css/main.css">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" crossorigin="anonymous">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" crossorigin="anonymous" />
 

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
    
    <script>hljs.initHighlightingOnLoad();</script>






<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>
 <meta name="generator" content="Hugo 0.125.2">
        

        
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-EVC27KVMVZ"></script>
            <script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments)};
              gtag('js', new Date());
              gtag('config', 'G-EVC27KVMVZ');
            </script>
        

        
            <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        

        
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/vaakash/socializer@2f749eb/css/socializer.min.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.3/css/all.css">
    
        


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
    
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




    </head>

    <body>
        


        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand visible-xs" href="#">Linear Regression Part 8 - Stochastic Gradient Descent</a>
                    <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                </div>
                <div class="collapse navbar-collapse">
                    
                        <ul class="nav navbar-nav">
                            
                                <li><a href="/">Home</a></li>
                            
                                <li><a href="/about/">About</a></li>
                            
                                <li><a href="/post/">Tech Posts</a></li>
                            
                                <li><a href="/project/">Tech Projects</a></li>
                            
                                <li><a href="/ww2/">World War 2</a></li>
                            
                        </ul>
                    
                    
                        <ul class="nav navbar-nav navbar-right">
                            
                                <li class="navbar-icon"><a href="mailto:carmelafa@hotmail.com"><i class="fas fa-envelope"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://github.com/carmelgafa/"><i class="fab fa-github"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://www.linkedin.com/in/carmel-gafa-200aa37/"><i class="fab fa-linkedin"></i></a></li>
                            
                        </ul>
                    
                </div>
            </div>
        </nav>







<div class="sr-sharebar sr-sb-vl sr-sb-left">
  <div class="socializer a sr-32px sr-opacity sr-vertical sr-icon-white sr-pad">
    <span class="sr-email">
      <a href="mailto:?subject=Linear%20Regression%20Part%208%20-%20Stochastic%20Gradient%20Descent&amp;body=Linear%20Regression%20Part%208%20-%20Stochastic%20Gradient%20Descent%2c%20by%20Carmel%20Gafa%0a%0a%3cnil%3e%0a%0ahttps%3a%2f%2fcarmelgafa.com%2fpost%2fml_linearreg_stochasticgd%2f%0a" target="_blank" title="Share to Email">
        <i class="fa fa-envelope"></i>
      </a>
    </span>
    <span class="sr-rss">
      <a href="" target="_blank" title="Share to RSS">
        <i class="fa fa-rss"></i>
      </a>
    </span>
    <span class="sr-whatsapp">
      <a href="https://api.whatsapp.com/send?text=https%3a%2f%2fcarmelgafa.com%2fpost%2fml_linearreg_stochasticgd%2f" target="_blank" title="Share to WhatsApp">
        <i class="fab fa-whatsapp"></i>
      </a>
    </span>
    <span class="sr-print">
      <a href="https://www.printfriendly.com/print?url=https%3a%2f%2fcarmelgafa.com%2fpost%2fml_linearreg_stochasticgd%2f" target="_blank" title="Print">
        <i class="fa fa-print"></i>
      </a>
    </span>
  </div>
</div>


<main>

    <div>
        <h2><b>Linear Regression Part 8 - Stochastic Gradient Descent</b></h2>
        <h5>Mon January 31, 2022</h5>
        
<a href="//localhost:1313/tags/machine-learning"><kbd class="item-tag">machine-learning</kbd></a>

<a href="//localhost:1313/tags/linear-regression"><kbd class="item-tag">linear-regression</kbd></a>

<a href="//localhost:1313/tags/gradient-descent"><kbd class="item-tag">gradient-descent</kbd></a>

<a href="//localhost:1313/tags/python"><kbd class="item-tag">python</kbd></a>


    </div>

    <div align="start" class="content"><p>In a previous post, we have discussed the gradient descent algorithm for linear regression applied to multiple features. As the size of the training dataset increases, gradient descent becomes very computationally expensive. In particular, if we consider the computation of the cost function,</p>
<p>$$J = \frac{1}{2m} \sum_{i=1}^m \left( \hat{y}^{(i)} - {y}^{(i)} \right)^2$$,</p>
<p>which is a calculation that we need to compute for each training data iteration; we can can see that the cost function is expensive as m increases.</p>
<p>Stochastic gradient descent is a variant of gradient descent where <strong>coefficients are updated after each observation</strong>, and it is therefore better suited for large datasets. Therefore if we consider an observation $i$ of the training dataset, we can calculate the cost of the observation, or how well our hypothesis function predicts the observation as,</p>
<p>$$Cost(\beta, (x^{(i)}, y^{(i)})) = \frac{1}{2} \left(\hat{y}^{(i)} - {y}^{(i)} \right)^2$$</p>
<p>We can therefore calculate the cost function as</p>
<p>$$J(\beta) = \frac{1}{m} \sum_{i=1}^m \left( \hat{y}^{(i)} - {y}^{(i)} \right)^2$$</p>
<p>Random Gradient Descent can be implemented as follows:</p>
<ul>
<li>
<p>Shuffle the training dataset, thus making sure that the order of the observations is random.</p>
</li>
<li>
<p>For each observation:</p>
<ul>
<li>$$\begin{pmatrix}
a_0 \\
a_1 \\
\vdots \\
a_n
\end{pmatrix} :=
\begin{pmatrix}
a_0 \\
a_1 \\
\vdots \\
a_n
\end{pmatrix} -
\alpha
\begin{pmatrix}
x_0^{(i)}\\
x_1^{(i)}\\
\vdots\\
x_n^{(i)}
\end{pmatrix}
\cdot
\begin{pmatrix}
\hat{y}^{(i)} - {y}^{(i)}
\end{pmatrix}
$$</li>
</ul>
</li>
</ul>
<p>Where $m$ is the number of training data points.</p>
<p>We can execute the above equation for a fixed number of iterations, where convergence is usually achieved. The code to implement this algorithm is as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib
</span></span><span style="display:flex;"><span>matplotlib<span style="color:#f92672">.</span>rcParams[<span style="color:#e6db74">&#39;text.usetex&#39;</span>] <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sys
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stochastic_gradient_descent</span>(file, alpha, max_epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Implementation of Stochastic Gradient Descent
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Exit condition: max_epochs epochs
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># load the training data</span>
</span></span><span style="display:flex;"><span>    full_filename <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>dirname(__file__), file)
</span></span><span style="display:flex;"><span>    data_set <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(full_filename, delimiter<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;,&#39;</span>, header<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, index_col<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># training_data = training_data.sample(frac=1).reset_index(drop=True)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># divide the data into features and labels</span>
</span></span><span style="display:flex;"><span>    X <span style="color:#f92672">=</span> data_set<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;y&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># add a column of ones to the features matrix to account for the intercept, a0</span>
</span></span><span style="display:flex;"><span>    X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>insert(X, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Y <span style="color:#f92672">=</span> data_set[<span style="color:#e6db74">&#39;y&#39;</span>]<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># length of the training data</span>
</span></span><span style="display:flex;"><span>    m <span style="color:#f92672">=</span> len(Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize the y_hat vector to 0</span>
</span></span><span style="display:flex;"><span>    y_hat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros(len(Y))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># beta will hold the values of the coefficients, hence it will be  the size </span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># of a row of the X matrix</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize beta to random values</span>
</span></span><span style="display:flex;"><span>    beta <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random(len(X[<span style="color:#ae81ff">0</span>]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize the number of epochs</span>
</span></span><span style="display:flex;"><span>    epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># loop until exit condition is met</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        i <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">0</span>, m)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># print(f&#39;Minibatch: {i}&#39;)</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> X[i]
</span></span><span style="display:flex;"><span>        y <span style="color:#f92672">=</span> Y[i]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># calculate the hypothesis function for all training data</span>
</span></span><span style="display:flex;"><span>        y_hat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(beta, x<span style="color:#f92672">.</span>T)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#  calculate the residuals</span>
</span></span><span style="display:flex;"><span>        residuals <span style="color:#f92672">=</span> y_hat <span style="color:#f92672">-</span> y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># calculate the new value of beta</span>
</span></span><span style="display:flex;"><span>        beta <span style="color:#f92672">-=</span> (alpha <span style="color:#f92672">*</span> residuals <span style="color:#f92672">*</span> x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        epochs <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># check if the cost function is close enough to 0, if so, break or if the number of </span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># iterations is greater than the threshold, break</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> epochs <span style="color:#f92672">&gt;</span> (m<span style="color:#f92672">*</span>max_epochs):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># calculate the cost for the training data and return the beta values and </span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># the number of iterations and the cost</span>
</span></span><span style="display:flex;"><span>    y_hat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(beta, X<span style="color:#f92672">.</span>T)
</span></span><span style="display:flex;"><span>    residuals <span style="color:#f92672">=</span> y_hat <span style="color:#f92672">-</span> Y
</span></span><span style="display:flex;"><span>    cost <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(residuals, residuals) <span style="color:#f92672">/</span> ( <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> m)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> beta, cost
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">from</span> timeit <span style="color:#f92672">import</span> default_timer <span style="color:#66d9ef">as</span> timer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    file <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;data.csv&#39;</span>
</span></span><span style="display:flex;"><span>    alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0001</span>
</span></span><span style="display:flex;"><span>    max_epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>    start <span style="color:#f92672">=</span> timer()
</span></span><span style="display:flex;"><span>    beta, cost <span style="color:#f92672">=</span> stochastic_gradient_descent(file, alpha, max_epochs) 
</span></span><span style="display:flex;"><span>    end <span style="color:#f92672">=</span> timer()
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Time: </span><span style="color:#e6db74">{</span>end <span style="color:#f92672">-</span> start<span style="color:#e6db74">}</span><span style="color:#e6db74">, beta: </span><span style="color:#e6db74">{</span>beta<span style="color:#e6db74">}</span><span style="color:#e6db74">, cost: </span><span style="color:#e6db74">{</span>cost<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><h3 id="exit-criteria-considerations">Exit Criteria Considerations</h3>
<p>A critical consideration in the above algorithm is that the aspect of convergence measurement is wholly taken out, and the algorithm terminates after a fixed number of epochs. A better approach is to reserve a portion of the data for validation and then use the remaining data for training. The validation set is then used to calculate the cost function and the algorithm terminates when the cost function converges. An implementation of this approach is as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib
</span></span><span style="display:flex;"><span>matplotlib<span style="color:#f92672">.</span>rcParams[<span style="color:#e6db74">&#39;text.usetex&#39;</span>] <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sys
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stochastic_gradient_descent</span>(file, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0023</span>, epochs_threshold<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, costdifference_threshold<span style="color:#f92672">=</span><span style="color:#ae81ff">0.00001</span>, plot<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Implementation of Stochastic Gradient Descent
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># load the training data</span>
</span></span><span style="display:flex;"><span>    full_filename <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>dirname(__file__), file)
</span></span><span style="display:flex;"><span>    data_set <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(full_filename, delimiter<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;,&#39;</span>, header<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, index_col<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># create train and test sets</span>
</span></span><span style="display:flex;"><span>    mask <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(len(data_set)) <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0.8</span>
</span></span><span style="display:flex;"><span>    training_data <span style="color:#f92672">=</span> data_set[mask]
</span></span><span style="display:flex;"><span>    validation_data <span style="color:#f92672">=</span> data_set[<span style="color:#f92672">~</span>mask]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># divide the data into features and labels</span>
</span></span><span style="display:flex;"><span>    X_train <span style="color:#f92672">=</span> data_set<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;y&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># add a column of ones to the features matrix to account for the intercept, a0</span>
</span></span><span style="display:flex;"><span>    X_train <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>insert(X_train, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    Y_train <span style="color:#f92672">=</span> data_set[<span style="color:#e6db74">&#39;y&#39;</span>]<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    X_validation <span style="color:#f92672">=</span> validation_data<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;y&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>    X_validation <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>insert(X_validation, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    Y_validation <span style="color:#f92672">=</span> validation_data[<span style="color:#e6db74">&#39;y&#39;</span>]<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># length of the training data</span>
</span></span><span style="display:flex;"><span>    m <span style="color:#f92672">=</span> len(Y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize the y_hat vector to 0</span>
</span></span><span style="display:flex;"><span>    y_hat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros(len(Y_train))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># beta will hold the values of the coefficients, hence it will be  the size </span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># of a row of the X matrix</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize beta to random values</span>
</span></span><span style="display:flex;"><span>    beta <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random(len(X_train[<span style="color:#ae81ff">0</span>]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize the number of epochs</span>
</span></span><span style="display:flex;"><span>    count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    previous_validation_cost <span style="color:#f92672">=</span> sys<span style="color:#f92672">.</span>float_info<span style="color:#f92672">.</span>max
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># loop until exit condition is met</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        i <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">0</span>, m)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># print(f&#39;Minibatch: {i}&#39;)</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> X_train[i]
</span></span><span style="display:flex;"><span>        y <span style="color:#f92672">=</span> Y_train[i]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># calculate the hypothesis function for all training data</span>
</span></span><span style="display:flex;"><span>        y_hat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(beta, x<span style="color:#f92672">.</span>T)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#  calculate the residuals</span>
</span></span><span style="display:flex;"><span>        residuals <span style="color:#f92672">=</span> y_hat <span style="color:#f92672">-</span> y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># calculate the new value of beta</span>
</span></span><span style="display:flex;"><span>        beta <span style="color:#f92672">-=</span> (alpha <span style="color:#f92672">*</span> residuals <span style="color:#f92672">*</span> x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        count <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> count <span style="color:#f92672">%</span> <span style="color:#ae81ff">1000</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            y_hat_validation <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(beta, X_validation<span style="color:#f92672">.</span>T)
</span></span><span style="display:flex;"><span>            residuals_validation <span style="color:#f92672">=</span> y_hat_validation <span style="color:#f92672">-</span> Y_validation
</span></span><span style="display:flex;"><span>            cost_validation <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(residuals_validation, residuals_validation) <span style="color:#f92672">/</span> ( <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> len(Y_validation))
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> abs(previous_validation_cost <span style="color:#f92672">-</span> cost_validation) <span style="color:#f92672">&lt;</span> costdifference_threshold:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                previous_validation_cost <span style="color:#f92672">=</span> cost_validation
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># uncomment this line to see details</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(f&#39;Epoch: {count/m} Cost: {cost_validation} beta: {beta}&#39;)</span>
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># check if the cost function is close enough to 0, if so, break or if the number of </span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># iterations is greater than the threshold, break</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (count<span style="color:#f92672">/</span>m) <span style="color:#f92672">&gt;</span> (epochs_threshold):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># calculate the cost for the training data and return the beta values and </span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># the number of iterations and the cost</span>
</span></span><span style="display:flex;"><span>    y_hat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(beta, X_train<span style="color:#f92672">.</span>T)
</span></span><span style="display:flex;"><span>    residuals <span style="color:#f92672">=</span> y_hat <span style="color:#f92672">-</span> Y_train
</span></span><span style="display:flex;"><span>    cost <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(residuals, residuals) <span style="color:#f92672">/</span> ( <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> m)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> beta, count, cost
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">from</span> timeit <span style="color:#f92672">import</span> default_timer <span style="color:#66d9ef">as</span> timer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    file <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;data.csv&#39;</span>
</span></span><span style="display:flex;"><span>    alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.00033</span>
</span></span><span style="display:flex;"><span>    epochs_threshold <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>    costdifference_threshold <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.005</span>
</span></span><span style="display:flex;"><span>    plot <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    start <span style="color:#f92672">=</span> timer()
</span></span><span style="display:flex;"><span>    beta, count, cost <span style="color:#f92672">=</span> stochastic_gradient_descent(file, alpha, epochs_threshold, costdifference_threshold, plot)
</span></span><span style="display:flex;"><span>    end <span style="color:#f92672">=</span> timer()
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Time: </span><span style="color:#e6db74">{</span>end <span style="color:#f92672">-</span> start<span style="color:#e6db74">}</span><span style="color:#e6db74">, beta: </span><span style="color:#e6db74">{</span>beta<span style="color:#e6db74">}</span><span style="color:#e6db74">, count: </span><span style="color:#e6db74">{</span>count<span style="color:#e6db74">}</span><span style="color:#e6db74">, cost: </span><span style="color:#e6db74">{</span>cost<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><h3 id="conclusion">Conclusion</h3>
<p>In this post, we have seen how the coefficients of the linear regression model can be optimized using the stochastic gradient descent algorithm. We have also seen different ways to determine exit criteria for the algorithm. We have also seen how to implement the algorithm in Python.</p>
</div>


    <br/>
    <br/>
    <br/>
    
    
    
        <h4 class="page-header"><b>Related</b></h4>
         <div class="item">

    
    
    

    
      

    <h4><a href="/post/ml_logistic_regression/">Logistic Regression</a></h4>
    <h5>Derivation of logistic regression</h5>
    
<a href="//localhost:1313/tags/machine-learning"><kbd class="item-tag">machine-learning</kbd></a>



</div>
  <div class="item">

    
    
    

    
    

    <h4><a href="/post/azureml_end2end_validation/">Notes about Azure ML, Part 11 - Model Validation in AzureML</a></h4>
    <h5>March 9, 2023</h5>
    
<a href="//localhost:1313/tags/machine-learning"><kbd class="item-tag">machine-learning</kbd></a>

<a href="//localhost:1313/tags/azure-ml"><kbd class="item-tag">azure ml</kbd></a>

<a href="//localhost:1313/tags/hyperparameter-tuning"><kbd class="item-tag">hyperparameter tuning</kbd></a>

<a href="//localhost:1313/tags/model-optimization"><kbd class="item-tag">model optimization</kbd></a>



</div>
  <div class="item">

    
    
    

    
    

    <h4><a href="/post/type2fuzzy_it2fs_typereduction_example/">Paper Implementation - Uncertain rule-based fuzzy logic systems Introduction and new directions-Jerry M. Mendel; Prentice-Hall, PTR, Upper Saddle River, NJ, 2001,    555pp., ISBN 0-13-040969-3. Example 9-4, page 261</a></h4>
    <h5>October 8, 2022</h5>
    
<a href="//localhost:1313/tags/type2-fuzzy"><kbd class="item-tag">type2-fuzzy</kbd></a>

<a href="//localhost:1313/tags/type2-fuzzy-library"><kbd class="item-tag">type2-fuzzy-library</kbd></a>

<a href="//localhost:1313/tags/fuzzy"><kbd class="item-tag">fuzzy</kbd></a>

<a href="//localhost:1313/tags/python"><kbd class="item-tag">python</kbd></a>

<a href="//localhost:1313/tags/it2fs"><kbd class="item-tag">IT2FS</kbd></a>

<a href="//localhost:1313/tags/paper-workout"><kbd class="item-tag">paper-workout</kbd></a>



</div>
 
    

    
    
        <h4 class="page-header"><b>Comments</b></h4>
        <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "carmelgafa-com-1" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    

</main>

        

        <div>

    <script type="text/javascript" 
    src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" 
    data-name="bmc-button" data-slug="carmelgafa" data-color="#FFDD00" data-emoji=""  
    data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#000000" 
    data-font-color="#000000" data-coffee-color="#ffffff" ></script>

</div>
        <br>
        <br>
        
<div id="theme-tagcloud" class="col-sm-12" style="margin-bottom: 15px;">
  
  
  
  
  
  
  <a href="/tags/machine-learning" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >machine-learning <span class="badge">27</span></a>
  
  
  
  
  <a href="/tags/python" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >python <span class="badge">21</span></a>
  
  
  
  
  <a href="/tags/fuzzy" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >fuzzy <span class="badge">14</span></a>
  
  
  
  
  <a href="/tags/azure%20ml" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >azure ml <span class="badge">11</span></a>
  
  
  
  
  <a href="/tags/hugo_cms" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >hugo_cms <span class="badge">11</span></a>
  
  
  
  
  <a href="/tags/linear-regression" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >linear-regression <span class="badge">10</span></a>
  
  
  
  
  <a href="/tags/gradient-descent" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >gradient-descent <span class="badge">9</span></a>
  
  
  
  
  <a href="/tags/type2-fuzzy" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >type2-fuzzy <span class="badge">8</span></a>
  
  
  
  
  <a href="/tags/type2-fuzzy-library" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >type2-fuzzy-library <span class="badge">8</span></a>
  
  
  
  
  <a href="/tags/type1-fuzzy" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >type1-fuzzy <span class="badge">5</span></a>
  
  
  
  
  <a href="/tags/cnc" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >cnc <span class="badge">4</span></a>
  
  
  
  
  <a href="/tags/dataset" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >dataset <span class="badge">4</span></a>
  
  
  
  
  <a href="/tags/datastore" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >datastore <span class="badge">4</span></a>
  
  
  
  
  <a href="/tags/it2fs" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >it2fs <span class="badge">4</span></a>
  
  
  
  
  <a href="/tags/excel" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >excel <span class="badge">3</span></a>
  
  
  
  
  <a href="/tags/paper-workout" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >paper-workout <span class="badge">3</span></a>
  
  
  
  
  <a href="/tags/r" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >r <span class="badge">3</span></a>
  
  
  
  
  <a href="/tags/c" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >c <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/c-sharp" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >c-sharp <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/experiment" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >experiment <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/hyperparameter%20tuning" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >hyperparameter tuning <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/iot" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >iot <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/model%20optimization" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >model optimization <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/programming" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >programming <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/robotics" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >robotics <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/weiszfeld_algorithm" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >weiszfeld_algorithm <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/arduino" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >arduino <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/automl" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >automl <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/classifier" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >classifier <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/computation" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >computation <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/cost-functions" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >cost-functions <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/development" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >development <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/embedded" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >embedded <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/fuzzy-logic" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >fuzzy-logic <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/game" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >game <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/javascript" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >javascript <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/learning" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >learning <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/mathjax" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >mathjax <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/maths" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >maths <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/mxchip" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >mxchip <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/pandas" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >pandas <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/pipeline" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >pipeline <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/random_walk" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >random_walk <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/roc" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >roc <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/tools" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >tools <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/vscode" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >vscode <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/wsl" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >wsl <span class="badge">1</span></a>
  
  
</div>

    </body>

</html>

