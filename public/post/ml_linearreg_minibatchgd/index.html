<!DOCTYPE html>
<html lang="en-us">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
        


        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Linear Regression Part 9 - Mini Batch Gradient Descent</title>
        
        <style>

    html body {
        font-family: 'Raleway', sans-serif;
        background-color: #f7f8fa;
    }

    :root {
        --accent: #660608;
        --border-width:  5px ;
    }

</style>


<link rel="stylesheet" href="//localhost:1313/css/main.css">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" crossorigin="anonymous">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" crossorigin="anonymous" />
 

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
    
    <script>hljs.initHighlightingOnLoad();</script>






<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>
 <meta name="generator" content="Hugo 0.125.2">
        

        
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-EVC27KVMVZ"></script>
            <script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments)};
              gtag('js', new Date());
              gtag('config', 'G-EVC27KVMVZ');
            </script>
        

        
            <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        

        
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/vaakash/socializer@2f749eb/css/socializer.min.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.3/css/all.css">
    
        


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
    
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




    </head>

    <body>
        


        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand visible-xs" href="#">Linear Regression Part 9 - Mini Batch Gradient Descent</a>
                    <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                </div>
                <div class="collapse navbar-collapse">
                    
                        <ul class="nav navbar-nav">
                            
                                <li><a href="/">Home</a></li>
                            
                                <li><a href="/about/">About</a></li>
                            
                                <li><a href="/post/">Tech Posts</a></li>
                            
                                <li><a href="/project/">Tech Projects</a></li>
                            
                                <li><a href="/ww2/">World War 2</a></li>
                            
                        </ul>
                    
                    
                        <ul class="nav navbar-nav navbar-right">
                            
                                <li class="navbar-icon"><a href="mailto:carmelafa@hotmail.com"><i class="fas fa-envelope"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://github.com/carmelgafa/"><i class="fab fa-github"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://www.linkedin.com/in/carmel-gafa-200aa37/"><i class="fab fa-linkedin"></i></a></li>
                            
                        </ul>
                    
                </div>
            </div>
        </nav>







<div class="sr-sharebar sr-sb-vl sr-sb-left">
  <div class="socializer a sr-32px sr-opacity sr-vertical sr-icon-white sr-pad">
    <span class="sr-email">
      <a href="mailto:?subject=Linear%20Regression%20Part%209%20-%20Mini%20Batch%20Gradient%20Descent&amp;body=Linear%20Regression%20Part%209%20-%20Mini%20Batch%20Gradient%20Descent%2c%20by%20Carmel%20Gafa%0a%0a%3cnil%3e%0a%0ahttps%3a%2f%2fcarmelgafa.com%2fpost%2fml_linearreg_minibatchgd%2f%0a" target="_blank" title="Share to Email">
        <i class="fa fa-envelope"></i>
      </a>
    </span>
    <span class="sr-rss">
      <a href="" target="_blank" title="Share to RSS">
        <i class="fa fa-rss"></i>
      </a>
    </span>
    <span class="sr-whatsapp">
      <a href="https://api.whatsapp.com/send?text=https%3a%2f%2fcarmelgafa.com%2fpost%2fml_linearreg_minibatchgd%2f" target="_blank" title="Share to WhatsApp">
        <i class="fab fa-whatsapp"></i>
      </a>
    </span>
    <span class="sr-print">
      <a href="https://www.printfriendly.com/print?url=https%3a%2f%2fcarmelgafa.com%2fpost%2fml_linearreg_minibatchgd%2f" target="_blank" title="Print">
        <i class="fa fa-print"></i>
      </a>
    </span>
  </div>
</div>


<main>

    <div>
        <h2><b>Linear Regression Part 9 - Mini Batch Gradient Descent</b></h2>
        <h5>Mon February 14, 2022</h5>
        
<a href="//localhost:1313/tags/machine-learning"><kbd class="item-tag">machine-learning</kbd></a>

<a href="//localhost:1313/tags/linear-regression"><kbd class="item-tag">linear-regression</kbd></a>

<a href="//localhost:1313/tags/gradient-descent"><kbd class="item-tag">gradient-descent</kbd></a>

<a href="//localhost:1313/tags/python"><kbd class="item-tag">python</kbd></a>


    </div>

    <div align="start" class="content"><p>In the <a href="/post/ml_linearreg_stochasticgd">last post</a> we compared the stochastic gradient descent algorithm to the batch gradient descent algorithm that we has discussed in <a href="/post/ml_linearreg_gradientdescent">a previous post</a>. We discussed that as the size of the training dataset increases, batch gradient descent, where we use all the examples of the training set in each iteration, becomes very computationally expensive and that we can therefore use stochastic gradient descent, where we use one example of the training set in each iteration, to have a more efficient way to approach the coefficients of our hypothesis function.</p>
<p>In this post we will discuss mini-batch gradient descent, where we use a number $k$ of the training set examples in each iteration, which is a variation of the thoughts of stochastic gradient descent. We will discuss the general idea of mini-batch gradient descent and how to implement it in Python.</p>
<p>Therefore we can consider our training dataset as a collection of $m/k$ mini batches;</p>
<p>$$\textbf{X} = \begin{pmatrix}
x_0^{(1)} &amp;\dots &amp; x_0^{(k)} &amp; x_0^{(k+1)} &amp; \dots &amp; x_0^{(2k)} &amp; \dots \dots &amp; x_0^{(m)}\\
x_1^{(1)} &amp;\dots &amp; x_1^{(k)} &amp; x_1^{(k+1)} &amp; \dots &amp; x_1^{(2k)} &amp; \dots \dots &amp; x_1^{(m)}\\
\vdots     &amp; &amp; \vdots     &amp; \vdots       &amp;  &amp; \vdots      &amp;  &amp; \vdots    \\
x_n^{(1)} &amp;\dots &amp; x_n^{(k)} &amp; x_n^{(k+1)} &amp; \dots &amp; x_n^{(2k)} &amp; \dots \dots &amp; x_n^{(m)}\\
\end{pmatrix}$$
$$Dim:[n \times m]$$</p>
<p>Therefore the matrix $X$ can be represented by a matrix of mini batches,</p>
<p>$$\textbf{X} = \begin{pmatrix}
X^{ \{  1 \} } &amp; X^{ \{  2 \} } &amp; \dots &amp; X^{ \{  m/k \} }\\
\end{pmatrix}$$</p>
<p>where $X^{ \{  1 \} }$ represents the first mini batch, $X^{ \{  2 \} }$ represents the second mini batch, and so on, such that;</p>
<p>$$X^{ \{  1 \} } = \begin{pmatrix}
x_0^{(1)} &amp;\dots &amp; x_0^{(k)} \\
x_1^{(1)} &amp;\dots &amp; x_1^{(k)} \\
\vdots     &amp; &amp; \vdots        \\
x_n^{(1)} &amp;\dots &amp; x_n^{(k)} \\
\end{pmatrix}$$
$$Dim:[n \times k]$$</p>
<p>Similarly for the $Y$ vector,</p>
<p>$$\textbf{Y} = \begin{pmatrix}
Y^{ \{  1 \} } &amp; Y^{ \{  2 \} } &amp; \dots &amp; Y^{ \{  m/k \} }\\
\end{pmatrix}$$</p>
<p>Calculating the hypothesis function for a mini-batch of training data, we can write the following equation:</p>
<p>We can now calculate the hypothesis function for the first mini batch as a matrix multiplication:</p>
<p>$$\begin{pmatrix}
\hat{y}^{(1)} \\
\hat{y}^{(2)} \\
\vdots \\
\hat{y}^{(k)}
\end{pmatrix} =
\begin{pmatrix}
x_0^{(1)} &amp; x_1^{(1)} &amp; \dots &amp; x_n^{(1)} \\
x_0^{(2)} &amp; x_1^{(2)} &amp; \dots &amp; x_n^{(2)} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
x_0^{(k)} &amp; x_1^{(k)} &amp; \dots &amp; x_n^{(k)}
\end{pmatrix}
\begin{pmatrix}
a_0 \\
a_1 \\
\vdots \\
a_n
\end{pmatrix}
$$
$$Dim:[k \times n] \cdot [n \times 1]$$</p>
<p>$$ \hat{Y}^{ \{ 1 \}}  = \left( {X}^{ \{ 1 \}} \right)^T \beta$$</p>
<p>We can therefore update the coefficients of our hypothesis function from this mini-batch as follows:</p>
<p>$$\begin{pmatrix}
a_0 \\
a_1 \\
\vdots \\
a_n
\end{pmatrix} :=
\begin{pmatrix}
a_0 \\
a_1 \\
\vdots \\
a_n
\end{pmatrix} -
\frac{\alpha}{k}
\begin{pmatrix}
x_0^{(1)} &amp; \dots &amp; x_0^{(k)}\\
x_1^{(1)} &amp; \dots &amp; x_1^{(k)}\\
\vdots&amp;&amp;\vdots\\
x_n^{(1)} &amp; \dots &amp; x_n^{(k)}\\
\end{pmatrix}
\cdot
\begin{pmatrix}
\hat{y}^{(1)} - {y}^{(1)} \\
\hat{y}^{(2)} - {y}^{(2)} \\
\vdots \\
\hat{y}^{(k)} - {y}^{(k)}
\end{pmatrix}
$$
$$Dim:[n \times k] \cdot [k \times 1]$$</p>
<p>or</p>
<p>$$\beta := \beta -\frac{\alpha}{k} \textbf{X} \cdot \textbf{R}$$</p>
<p>The cost function for the mini-batch gradient descent algorithm is:</p>
<p>$$\textbf{J} = \frac{1}{k} \sum_{i=1}^{k} (\hat{y}^{(i)} - y^{(i)})^2 $$</p>
<p>We notice that this is very similar to batch gradient descent, but in this case we are considering only a batch of $k$ examples of the training set. In this case, however an epoch will update the coefficients of our hypothesis function $m/k$ times instead of only once as in the case of batch gradient descent.</p>
<p>The following code will implement mini-batch gradient descent.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib
</span></span><span style="display:flex;"><span>matplotlib<span style="color:#f92672">.</span>rcParams[<span style="color:#e6db74">&#39;text.usetex&#39;</span>] <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sys
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">minibatch_gradient_descent</span>(file:str, alpha:float<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0023</span>, batch_size:int<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, epochs_threshold:int<span style="color:#f92672">=</span><span style="color:#ae81ff">100000</span>, costdifference_threshold:float<span style="color:#f92672">=</span><span style="color:#ae81ff">0.00001</span>, plot:bool<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># load the training data</span>
</span></span><span style="display:flex;"><span>    full_filename <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>dirname(__file__), file)
</span></span><span style="display:flex;"><span>    training_data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(full_filename, delimiter<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;,&#39;</span>, header<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, index_col<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># training_data = training_data.sample(frac=1).reset_index(drop=True)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># divide the data into features and labels</span>
</span></span><span style="display:flex;"><span>    X <span style="color:#f92672">=</span> training_data<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;y&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># add a column of ones to the features matrix to account for the intercept, a0</span>
</span></span><span style="display:flex;"><span>    X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>insert(X, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Y <span style="color:#f92672">=</span> training_data[<span style="color:#e6db74">&#39;y&#39;</span>]<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># length of the training data</span>
</span></span><span style="display:flex;"><span>    m <span style="color:#f92672">=</span> len(Y)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Length of the training data: </span><span style="color:#e6db74">{</span>m<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize the y_hat vector to 0</span>
</span></span><span style="display:flex;"><span>    y_hat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros(len(Y))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># beta will hold the values of the coefficients, hence it will be  the size </span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># of a row of the X matrix</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize beta to random values</span>
</span></span><span style="display:flex;"><span>    beta <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random(len(X[<span style="color:#ae81ff">0</span>]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># minibatches setting</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># number of minibatches = m =&gt; stochastic gradient descent</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># number of minibatches = 1 =&gt; batch gradient descent</span>
</span></span><span style="display:flex;"><span>    minibatch_size <span style="color:#f92672">=</span> int(m<span style="color:#f92672">/</span>batch_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize the number of epochs</span>
</span></span><span style="display:flex;"><span>    epoch_count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># initialize the previous cost function value to a large number</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># previous_cost = sys.float_info.max</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># store the cost function and a2 values for plotting</span>
</span></span><span style="display:flex;"><span>    costs <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    a_2s <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    previous_cumulative_cost <span style="color:#f92672">=</span> sys<span style="color:#f92672">.</span>float_info<span style="color:#f92672">.</span>max
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># loop until exit condition is met</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        cumulative_cost <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(batch_size):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(f&#39;Minibatch: {i}&#39;)</span>
</span></span><span style="display:flex;"><span>            minibatch_X <span style="color:#f92672">=</span> X[i<span style="color:#f92672">*</span>minibatch_size:(i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>minibatch_size]
</span></span><span style="display:flex;"><span>            minibatch_Y <span style="color:#f92672">=</span> Y[i<span style="color:#f92672">*</span>minibatch_size:(i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>minibatch_size]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># calculate the hypothesis function for all training data</span>
</span></span><span style="display:flex;"><span>            y_hat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(beta, minibatch_X<span style="color:#f92672">.</span>T)
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">#  calculate the residuals</span>
</span></span><span style="display:flex;"><span>            residuals <span style="color:#f92672">=</span> y_hat <span style="color:#f92672">-</span> minibatch_Y
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># calculate the new value of beta</span>
</span></span><span style="display:flex;"><span>            beta <span style="color:#f92672">-=</span> ( alpha <span style="color:#f92672">/</span> minibatch_size)  <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>dot(residuals, minibatch_X)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># calculate the cost function</span>
</span></span><span style="display:flex;"><span>            cost <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(residuals, residuals) <span style="color:#f92672">/</span> ( <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> minibatch_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            cumulative_cost <span style="color:#f92672">+=</span> cost
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># increase the number of iterations</span>
</span></span><span style="display:flex;"><span>        epoch_count <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># record the cost and a1 values for plotting</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     costs.append(cost)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     a_2s.append(__beta[2])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        cost_difference <span style="color:#f92672">=</span> previous_cumulative_cost <span style="color:#f92672">-</span> cumulative_cost
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># print(f&#39;Epoch: {epochs}, average cost: {(cumulative_cost/minibatches_number):.3f}, beta: {beta}&#39;)</span>
</span></span><span style="display:flex;"><span>        previous_cumulative_cost <span style="color:#f92672">=</span> cumulative_cost
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># check if the cost function is diverging, if so, break</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># if cost_difference &lt; 0:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     print(f&#39;Cost function is diverging. Stopping training.&#39;)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     break</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># check if the cost function is close enough to 0, if so, break or if the number of </span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># iterations is greater than the threshold, break</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> abs(cost_difference) <span style="color:#f92672">&lt;</span> costdifference_threshold <span style="color:#f92672">or</span> epoch_count <span style="color:#f92672">&gt;</span> epochs_threshold:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># # plot the cost function and a1 values</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># plt.plot(a_2s[3:], costs[3:], &#39;--bx&#39;, color=&#39;lightblue&#39;, mec=&#39;red&#39;)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># plt.xlabel(&#39;a2&#39;)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># plt.ylabel(&#39;cost&#39;)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># plt.title(r&#39;Cost Function vs. a1, with $\alpha$ =&#39; + str(__alpha))</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># plt.show()</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># calculate the cost for the training data and return the beta values and </span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># the number of iterations and the cost</span>
</span></span><span style="display:flex;"><span>    y_hat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(beta, X<span style="color:#f92672">.</span>T)
</span></span><span style="display:flex;"><span>    residuals <span style="color:#f92672">=</span> y_hat <span style="color:#f92672">-</span> Y
</span></span><span style="display:flex;"><span>    cost <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(residuals, residuals) <span style="color:#f92672">/</span> ( <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> m)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> beta, epoch_count, cost
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">from</span> timeit <span style="color:#f92672">import</span> default_timer <span style="color:#66d9ef">as</span> timer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    file <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;data.csv&#39;</span>
</span></span><span style="display:flex;"><span>    alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.00023</span>
</span></span><span style="display:flex;"><span>    epochs_threshold <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    costdifference_threshold <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.00001</span>
</span></span><span style="display:flex;"><span>    plot <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>    batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    start <span style="color:#f92672">=</span> timer()
</span></span><span style="display:flex;"><span>    beta, epoch_count, cost <span style="color:#f92672">=</span> minibatch_gradient_descent(file, alpha, batch_size, epochs_threshold, costdifference_threshold, plot)
</span></span><span style="display:flex;"><span>    end <span style="color:#f92672">=</span> timer()
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Time: </span><span style="color:#e6db74">{</span>end <span style="color:#f92672">-</span> start<span style="color:#e6db74">}</span><span style="color:#e6db74"> beta: </span><span style="color:#e6db74">{</span>beta<span style="color:#e6db74">}</span><span style="color:#e6db74">, epoch_count: </span><span style="color:#e6db74">{</span>epoch_count<span style="color:#e6db74">}</span><span style="color:#e6db74">, cost: </span><span style="color:#e6db74">{</span>cost<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div></div>


    <br/>
    <br/>
    <br/>
    
    
    
        <h4 class="page-header"><b>Related</b></h4>
         <div class="item">

    
    
    

    
      

    <h4><a href="/post/ml_logistic_regression/">Logistic Regression</a></h4>
    <h5>Derivation of logistic regression</h5>
    
<a href="//localhost:1313/tags/machine-learning"><kbd class="item-tag">machine-learning</kbd></a>



</div>
  <div class="item">

    
    
    

    
    

    <h4><a href="/post/azureml_end2end_validation/">Notes about Azure ML, Part 11 - Model Validation in AzureML</a></h4>
    <h5>March 9, 2023</h5>
    
<a href="//localhost:1313/tags/machine-learning"><kbd class="item-tag">machine-learning</kbd></a>

<a href="//localhost:1313/tags/azure-ml"><kbd class="item-tag">azure ml</kbd></a>

<a href="//localhost:1313/tags/hyperparameter-tuning"><kbd class="item-tag">hyperparameter tuning</kbd></a>

<a href="//localhost:1313/tags/model-optimization"><kbd class="item-tag">model optimization</kbd></a>



</div>
  <div class="item">

    
    
    

    
    

    <h4><a href="/post/type2fuzzy_it2fs_typereduction_example/">Paper Implementation - Uncertain rule-based fuzzy logic systems Introduction and new directions-Jerry M. Mendel; Prentice-Hall, PTR, Upper Saddle River, NJ, 2001,    555pp., ISBN 0-13-040969-3. Example 9-4, page 261</a></h4>
    <h5>October 8, 2022</h5>
    
<a href="//localhost:1313/tags/type2-fuzzy"><kbd class="item-tag">type2-fuzzy</kbd></a>

<a href="//localhost:1313/tags/type2-fuzzy-library"><kbd class="item-tag">type2-fuzzy-library</kbd></a>

<a href="//localhost:1313/tags/fuzzy"><kbd class="item-tag">fuzzy</kbd></a>

<a href="//localhost:1313/tags/python"><kbd class="item-tag">python</kbd></a>

<a href="//localhost:1313/tags/it2fs"><kbd class="item-tag">IT2FS</kbd></a>

<a href="//localhost:1313/tags/paper-workout"><kbd class="item-tag">paper-workout</kbd></a>



</div>
 
    

    
    
        <h4 class="page-header"><b>Comments</b></h4>
        <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "carmelgafa-com-1" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    

</main>

        

        <div>

    <script type="text/javascript" 
    src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" 
    data-name="bmc-button" data-slug="carmelgafa" data-color="#FFDD00" data-emoji=""  
    data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#000000" 
    data-font-color="#000000" data-coffee-color="#ffffff" ></script>

</div>
        <br>
        <br>
        
<div id="theme-tagcloud" class="col-sm-12" style="margin-bottom: 15px;">
  
  
  
  
  
  
  <a href="/tags/machine-learning" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >machine-learning <span class="badge">27</span></a>
  
  
  
  
  <a href="/tags/python" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >python <span class="badge">21</span></a>
  
  
  
  
  <a href="/tags/fuzzy" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >fuzzy <span class="badge">14</span></a>
  
  
  
  
  <a href="/tags/azure%20ml" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >azure ml <span class="badge">11</span></a>
  
  
  
  
  <a href="/tags/hugo_cms" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >hugo_cms <span class="badge">11</span></a>
  
  
  
  
  <a href="/tags/linear-regression" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >linear-regression <span class="badge">10</span></a>
  
  
  
  
  <a href="/tags/gradient-descent" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >gradient-descent <span class="badge">9</span></a>
  
  
  
  
  <a href="/tags/type2-fuzzy" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >type2-fuzzy <span class="badge">8</span></a>
  
  
  
  
  <a href="/tags/type2-fuzzy-library" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >type2-fuzzy-library <span class="badge">8</span></a>
  
  
  
  
  <a href="/tags/type1-fuzzy" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >type1-fuzzy <span class="badge">5</span></a>
  
  
  
  
  <a href="/tags/cnc" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >cnc <span class="badge">4</span></a>
  
  
  
  
  <a href="/tags/dataset" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >dataset <span class="badge">4</span></a>
  
  
  
  
  <a href="/tags/datastore" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >datastore <span class="badge">4</span></a>
  
  
  
  
  <a href="/tags/it2fs" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >it2fs <span class="badge">4</span></a>
  
  
  
  
  <a href="/tags/excel" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >excel <span class="badge">3</span></a>
  
  
  
  
  <a href="/tags/paper-workout" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >paper-workout <span class="badge">3</span></a>
  
  
  
  
  <a href="/tags/r" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >r <span class="badge">3</span></a>
  
  
  
  
  <a href="/tags/c" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >c <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/c-sharp" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >c-sharp <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/experiment" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >experiment <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/hyperparameter%20tuning" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >hyperparameter tuning <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/iot" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >iot <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/model%20optimization" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >model optimization <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/programming" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >programming <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/robotics" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >robotics <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/weiszfeld_algorithm" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >weiszfeld_algorithm <span class="badge">2</span></a>
  
  
  
  
  <a href="/tags/arduino" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >arduino <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/automl" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >automl <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/classifier" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >classifier <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/computation" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >computation <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/cost-functions" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >cost-functions <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/development" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >development <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/embedded" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >embedded <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/fuzzy-logic" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >fuzzy-logic <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/game" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >game <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/javascript" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >javascript <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/learning" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >learning <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/mathjax" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >mathjax <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/maths" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >maths <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/mxchip" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >mxchip <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/pandas" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >pandas <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/pipeline" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >pipeline <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/random_walk" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >random_walk <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/roc" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >roc <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/tools" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >tools <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/vscode" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >vscode <span class="badge">1</span></a>
  
  
  
  
  <a href="/tags/wsl" class="btn btn-default" role="button" style="text-transform: uppercase; font-size: 12px; padding-right: 5px; padding-left: 5px;" >wsl <span class="badge">1</span></a>
  
  
</div>

    </body>

</html>

