<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on </title>
    <link>//localhost:1313/tags/python/</link>
    <description>Recent content in Python on </description>
    <generator>Hugo 0.125.2</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 08 Oct 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="//localhost:1313/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Paper Implementation - Uncertain rule-based fuzzy logic systems Introduction and new directions-Jerry M. Mendel; Prentice-Hall, PTR, Upper Saddle River, NJ, 2001,    555pp., ISBN 0-13-040969-3. Example 9-4, page 261</title>
      <link>//localhost:1313/post/type2fuzzy_it2fs_typereduction_example/</link>
      <pubDate>Sat, 08 Oct 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/type2fuzzy_it2fs_typereduction_example/</guid>
      <description>In this post, we will validate the implementation of the Karnik-Mendel algorithm found in the type-2 fuzzy logic library with a worked example available in Mendel&amp;rsquo;s book &amp;ldquo;Uncertain rule-based fuzzy logic systems.&amp;rdquo;&#xA;The example calculates the centroid of interval type-2 fuzzy sets with uncertain means $m\in[m_1, m_2]$, where the UMF and LMF of the set are calculated as follows:&#xA;$exp \left[ -0.5 \times (\frac{x-m_1}{\sigma})^2 \right]$ ,$x&amp;lt;m_1$ $UMF(\tilde{A})=$ $1$ ,$m_1, \geq x \geq m_2$ $exp \left[ -0.</description>
    </item>
    <item>
      <title>Type Reduction of Interval Type-2 Fuzzy Sets</title>
      <link>//localhost:1313/post/type2fuzzy_it2fs_typereduction/</link>
      <pubDate>Wed, 06 Apr 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/type2fuzzy_it2fs_typereduction/</guid>
      <description>This post will look at Interval Type-2 fuzzy set (IT2FS) and its reduction. We have already discussed the basics of Type-2 fuzzy sets in a previous post, and we have seen that a general type-2 fuzzy set can be defined as follows:&#xA;$$\tilde{A}=\int_{x\in X}\int_{u\in J_{x}} \mu_{\tilde{A}}(x,u) / (x,u)$$&#xA;where $J_{x}\subseteq[0,1]$&#xA;And if, as an example, we consider the following general type-2 fuzzy set:&#xA;(1.0/0 + 0.5/0.2 + 0.3/0.4 + 0.1/0.6 )/1+ (0.</description>
    </item>
    <item>
      <title>Paper Implementation - C. Wagner and H. Hagras. &#39;Toward general type-2 fuzzy logic systems based on zSlices.&#39;</title>
      <link>//localhost:1313/post/type2fuzzy_paper_zslices/</link>
      <pubDate>Sun, 27 Mar 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/type2fuzzy_paper_zslices/</guid>
      <description>The paper by Wagner and Hagras explains the concept of zSlices as a way to implement type-2 fuzzy logic systems based on general type-2 fuzzy sets. The paper&amp;rsquo;s appendices contain numeric examples of centroid computation based on zSlices. This post describes the steps involved in implementing the paper by Wagner and Hagras. It also lists the results obtained and compares them with those listed in the original document.&#xA;Centroid of a zSliced Based Type-2 Set The general type-2 fuzzy set used in these examples will result in the potential computation of the centroid of $3^{11}$ wavy slices.</description>
    </item>
    <item>
      <title>Linear Regression, Part 10 - Analysis of Gradient Descent Algorithms; Results obtained</title>
      <link>//localhost:1313/post/ml_linearreg_gradientdescent_analysis/</link>
      <pubDate>Sat, 12 Mar 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/ml_linearreg_gradientdescent_analysis/</guid>
      <description>**In this series of posts we have discussed the basics of linear regression and they introduced the gradient descent algorithm. We have also discussed the stochastic gradient descent algorithm and the mini-batch gradient descent as variations of batch gradient descent that can possibly reduce the time to convergence of the algorithm.&#xA;In this post we will summarize what we have discussed so far, and focus on the results that we have obtained from the various gradient descent algorithms.</description>
    </item>
    <item>
      <title>Linear Regression Part 9 - Mini Batch Gradient Descent</title>
      <link>//localhost:1313/post/ml_linearreg_minibatchgd/</link>
      <pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/ml_linearreg_minibatchgd/</guid>
      <description>In the last post we compared the stochastic gradient descent algorithm to the batch gradient descent algorithm that we has discussed in a previous post. We discussed that as the size of the training dataset increases, batch gradient descent, where we use all the examples of the training set in each iteration, becomes very computationally expensive and that we can therefore use stochastic gradient descent, where we use one example of the training set in each iteration, to have a more efficient way to approach the coefficients of our hypothesis function.</description>
    </item>
    <item>
      <title>Linear Regression Part 8 - Stochastic Gradient Descent</title>
      <link>//localhost:1313/post/ml_linearreg_stochasticgd/</link>
      <pubDate>Mon, 31 Jan 2022 16:24:09 +0100</pubDate>
      <guid>//localhost:1313/post/ml_linearreg_stochasticgd/</guid>
      <description>In a previous post, we have discussed the gradient descent algorithm for linear regression applied to multiple features. As the size of the training dataset increases, gradient descent becomes very computationally expensive. In particular, if we consider the computation of the cost function,&#xA;$$J = \frac{1}{2m} \sum_{i=1}^m \left( \hat{y}^{(i)} - {y}^{(i)} \right)^2$$,&#xA;which is a calculation that we need to compute for each training data iteration; we can can see that the cost function is expensive as m increases.</description>
    </item>
    <item>
      <title>Linear Regression, Part 7 - Multivariate Gradient Descent</title>
      <link>//localhost:1313/post/ml_linearreg_multivariatedescent/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/ml_linearreg_multivariatedescent/</guid>
      <description>We have discussed the multivariate linear regression problem in the previous posts, and we have seen that in this case the hypothesis function becomes:&#xA;$$\hat{y} = a_0 + a_1 x_1 + a_2 x_2 + \dots + a_n x_n$$&#xA;If we define $x_0$, such that $x_0 = 1$, then the hypothesis function becomes:&#xA;$$\hat{y} = a_0 x_0 + a_1 x_1 + a_2 x_2 + \dots + a_n x_n$$&#xA;Let us now consider a dataset of $m$ points.</description>
    </item>
    <item>
      <title>Linear Regression, Part 6 - The Gradient Descent Algorithm, Univariate Considerations</title>
      <link>//localhost:1313/post/ml_linearreg_gradientdescent/</link>
      <pubDate>Fri, 07 Jan 2022 11:08:45 +0100</pubDate>
      <guid>//localhost:1313/post/ml_linearreg_gradientdescent/</guid>
      <description>We started this series of posts with an examination of Cost Functions, and then moved on to derive and implement the solution to the linear regression problem for a single variable We extended this to a multi-variable linear regression problem, and we derived and implemented the solution for this case. Our final comment was that as the number of variables increases, the solution becomes computationally prohibitive.&#xA;In this post, we will look at gradient descent, an iterative optimization algorithm used to find the minimum of a function.</description>
    </item>
    <item>
      <title>Linear Regression, Part 5 - Multivariate Solution Implementation in Python</title>
      <link>//localhost:1313/post/ml_linearreg_multivariatepython/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/ml_linearreg_multivariatepython/</guid>
      <description>In this post we will implement the multivariate linear regression model for 2 features in python. We gave already seen in the last post, that for this case, $a_0$, $a_1$ and $a_2$ can be solved by;&#xA;$$a_1 = \frac{ \sum_{i=1}^{n} X_{2i}^2 \sum_{i=1}^{n} X_{1i}y_i - \sum_{i=1}^{n} X_{1i}X_{2i} \sum_{i=1}^{n} X_{2i}y_i } {\sum_{i=1}^{n}X_{1i}^2 \sum_{i=1}^{n}X_{2i}^2 - (\sum_{i=1}^{n} X_{1i}X_{2i})^2}$$&#xA;$$a_2 = \frac{ \sum_{i=1}^{n} X_{1i}^2 \sum_{i=1}^{n} X_{2i}y_i - \sum_{i=1}^{n} X_{1i}x_{2i} \sum_{i=1}^{n} X_{1i}y_i } {\sum_{i=1}^{n}X_{1i}^2 \sum_{i=1}^{n}X_{2i}^2 - (\sum_{i=1}^{n} X_{1i}X_{2i})^2}$$</description>
    </item>
    <item>
      <title>Liner Regression, Part 4 - The Multi-variable scenario</title>
      <link>//localhost:1313/post/ml_linearreg_multivariate/</link>
      <pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/ml_linearreg_multivariate/</guid>
      <description>Introduction In previous posts we discussed the univariate linear regression model and how we can implement the model in python.&#xA;We have seen how we can fit a line, $\hat{y} = a_0 + a_1 x$, to a dataset of given points, and how linear regression techniques estimate the values of $a_0$ and $a_1$ using the cost functions. We have seen that the residual is the difference between the observed values and the predicted values, that is, for any point $i$,</description>
    </item>
    <item>
      <title>Linear Regression, Part 3 - Univariate Solution Implementation in Python</title>
      <link>//localhost:1313/post/ml_linearreg_univariatepython/</link>
      <pubDate>Tue, 21 Dec 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/ml_linearreg_univariatepython/</guid>
      <description>This post continues from the derivation of the univariate linear regression model as explained in the previous post. Here we will use the equations derived and the in practice to implement the model.&#xA;Univarite Function We start this discussion by considering the function used in this post. The function that we will use is&#xA;$$y = 2x + 15 + \xi$$&#xA;Where $\xi$ is a random variable that will introduce noise to the data.</description>
    </item>
    <item>
      <title>Liner Regression, Part 2 - Deriving the Univariate case</title>
      <link>//localhost:1313/post/ml_linearreg_univariatederivation/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/ml_linearreg_univariatederivation/</guid>
      <description>This post is a continuation of a previous post where the cost functions used in linear regression scenarios are used. We will start by revisiting the mean square error (MSE) cost function;&#xA;$$MSE = \frac{\sum_{i=1}^{n} ( \hat{y}_i-y_i )^{2} }{n}$$&#xA;which, as explained in the previous post, is&#xA;$$MSE = \frac{\sum_{i=1}^{n} (y_i-a_0-a_1 x_i)^{2} }{n}$$&#xA;The objective is to adjust $a_0$ and $a_1$ such that the MSE is minimized. This is achieved by deriving the MSE with respect to $a_0$ and $a_1$, and finding the minimum case by equating to zero.</description>
    </item>
    <item>
      <title>Paper Implementation - Mendel, Jerry M., and RI Bob John. &#39;Type-2 fuzzy sets made simple.&#39;</title>
      <link>//localhost:1313/post/type2fuzzy_paper_made_simple/</link>
      <pubDate>Wed, 27 Oct 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/type2fuzzy_paper_made_simple/</guid>
      <description>Introduction &amp;ldquo;Type-2 Fuzzy Sets made simple&amp;rdquo; is possibly the best paper to learn about Type-2 fuzzy sets and logic. It outlines all the definitions and concepts that are necessary to work with type-2 fuzzy sets in a clear and concise manner. This paper illustrates the implementation of all the examples prepared by Mendel and John using the type2fuzzy library.&#xA;This post is the first in a series aimed to illustrate the capabilities of the Type2FuzzyLibrary (https://pypi.</description>
    </item>
    <item>
      <title>Simple Python implementation of the Weiszfeld algorithm</title>
      <link>//localhost:1313/post/ml_weiszfeld_python/</link>
      <pubDate>Sun, 14 Mar 2021 15:32:17 +0100</pubDate>
      <guid>//localhost:1313/post/ml_weiszfeld_python/</guid>
      <description>Following is a simple implementation of the Weiszfeld algortihm that was discussed in a previous post in python.&#xA;import numpy as np import math from numpy import array def weiszfeld(points): max_error = 0.0000000001 x=np.array([point[0] for point in points]) y=np.array([point[1] for point in points]) ext_condition = True start_x = np.average(x) start_y = np.average(y) while ext_condition: sod = (((x - start_x)**2) + ((y - start_y)**2))**0.5 new_x = sum(x/sod) / sum(1/sod) new_y = sum(y/sod) / sum(1/sod) ext_condition = (abs(new_x - start_x) &amp;gt; max_error) or (abs(new_y - start_y) &amp;gt; max_error) start_y = new_y start_x = new_x print(new_x, new_y) if __name__==&amp;#34;__main__&amp;#34;: weiszfeld([(2,1), (12,2), (3,9), (13,11)]) </description>
    </item>
    <item>
      <title>Notes on Monte Carlo Simulation</title>
      <link>//localhost:1313/post/ml_random_walk/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/post/ml_random_walk/</guid>
      <description>Some notes taken from Prof. Guttag excellent discussion on the topic.&#xA;The technique was first developed by Stanislaw Ulam, a mathematician who worked on the Manhattan Project.&#xA;A method of estimating the value of an unknown quantity using the principles of inferential statistics.&#xA;Inferential Statistics Population : Set of examples Sample : proper subset of population Random sample tends to exhibit the same qualities as the population. Confidence depends on:</description>
    </item>
    <item>
      <title>Fuzzy Inference System implementation in Python</title>
      <link>//localhost:1313/post/type1fuzzy_pyton/</link>
      <pubDate>Wed, 24 Jun 2020 14:43:21 +0200</pubDate>
      <guid>//localhost:1313/post/type1fuzzy_pyton/</guid>
      <description>This article was first published in Towards Data Science.&#xA;Introduction In a previous article, we discussed the basics of fuzzy sets and fuzzy inferencing. The report also illustrated the construction of a possible control application using a fuzzy inferencing method. In this article, we will build a multi-input/multi-output fuzzy inference system using the Python programming language. It is assumed that the reader has a clear understanding of fuzzy inferencing and has read the article mentioned previously.</description>
    </item>
    <item>
      <title>Short notes about Pandas</title>
      <link>//localhost:1313/post/dev_pandas/</link>
      <pubDate>Mon, 30 Mar 2020 13:21:20 +0200</pubDate>
      <guid>//localhost:1313/post/dev_pandas/</guid>
      <description>I am currently using a lot more the Pandas library to load data into a fuzzy learning framework. This note summarizes my learning points on the library. For the process of this exercise the Wine Quality data set used by Cortes et all will be used&#xA;Pandas Terminology Series is a one-dimensional NumPy-like array. You can put any data type in here, and perform vectorized operations on it. A series is also a dictionary.</description>
    </item>
    <item>
      <title>Type-1 Fuzzy Variable</title>
      <link>//localhost:1313/post/type2fuzzy_type1_variable/</link>
      <pubDate>Sun, 08 Mar 2020 14:21:53 +0100</pubDate>
      <guid>//localhost:1313/post/type2fuzzy_type1_variable/</guid>
      <description>The Type1FuzzyVariable class in the library is a way to define and use linguistic variables.&#xA;By a linguistic variable we mean a variable whose values are words or sentences in a natural or artificial language. For example, Age is a linguistic variable if its values are linguistic rather than numerical, i.e.,young, not young, very young, quite young, old, not very old and not very young, etc., rather than 20, 21,22, 23 (Zadeh, Lotfi Asker.</description>
    </item>
    <item>
      <title>Interval Type-2 Fuzzy Sets Type Reduction</title>
      <link>//localhost:1313/post/type2fuzzy_libraryit2fs_reduction/</link>
      <pubDate>Mon, 03 Feb 2020 16:17:59 +0100</pubDate>
      <guid>//localhost:1313/post/type2fuzzy_libraryit2fs_reduction/</guid>
      <description>Jerry Mendel&amp;rsquo;s book can be safely considered as the Type-2 Fuzzy Logic bible. It is not an easy or inexpensive read, but definitely the best way to get to know the world of Type-2 Sets.&#xA;In this post a book example, where the centroid of a number of Interval Type-2 sets was calculated is replicated using the Type-2 Library.&#xA;Type reduction in these cases is carried out by using the function it2_kernikmendel_reduce(interval_set), and a crisp set, the centroid, is returned back.</description>
    </item>
    <item>
      <title>Type-2 Fuzzy Logic Library</title>
      <link>//localhost:1313/project/type2fuzzy_library/</link>
      <pubDate>Tue, 14 Jan 2020 09:34:11 +0100</pubDate>
      <guid>//localhost:1313/project/type2fuzzy_library/</guid>
      <description>A type-2 fuzzy logic library providing:&#xA;Ways to define and work with general type-2 fuzzy sets Ways to define and work with interval type-2 fuzzy sets Ways to generate z-sliced sets from general type-2 fuzzy sets Functions to perform wavy-slice type-reduction (Mendel-John) on general type-2 fuzzy sets Functions to perform interval type-2 reduction (Karnik-Mendel) Functions to perform partial-centroid type-reduction on general type-2 fuzzy sets Functions to perform defuzzification of type-1 fuzzy sets Tools to measure the performance of algorithms Tools to plot general, interval and z-sliced type-2 fuzzy sets and type-1 fuzzy sets and more Ways to define and work with type-1 fuzzy sets Ways to define and work with linguistic variables and more</description>
    </item>
    <item>
      <title>Loading Interval Type-2 Sets</title>
      <link>//localhost:1313/post/type2fuzzy_library_it2fs_loading/</link>
      <pubDate>Sun, 12 Jan 2020 15:09:43 +0100</pubDate>
      <guid>//localhost:1313/post/type2fuzzy_library_it2fs_loading/</guid>
      <description>Interval Type-2 Fuzzy Sets can be loaded by using one of the following methods:&#xA;From a set definition in a string. From a set definition in a file. The set definitions myst have the following format:&#xA;[0.1,&#x9;0.5]/1 + [0.2,&#x9;0.7]/2 + [0.3,&#x9;1.0]/3 +&#xD;[0.4,&#x9;1]/4 The following example illustrated the creation of IT2FS using these methods&#xA;from type2fuzzy import IntervalType2FuzzySet from type2fuzzy import it2_kernikmendel_reduce import os # load an it2fs from representation set_representation= &amp;#39;&amp;#39;&amp;#39;[0.</description>
    </item>
  </channel>
</rss>
